{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c4c8b7",
   "metadata": {},
   "source": [
    "# Completer Test\n",
    "\n",
    "This notebook is made for assessing the performence of the QPL completer alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3a957",
   "metadata": {},
   "source": [
    "## Generate Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4217b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danieloh/.conda/envs/qpl/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.prompters import PrompterRegistry\n",
    "from src.utils.generation import to_model_prompt, generate_batch\n",
    "import src.utils.paths as p\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 6\n",
    "MAX_NEW_TOKENS = 128\n",
    "MODEL_CKPT = \"output/models/855d8cb9_gemma-3-4b-it-qpl-composer-ds_train_batch_size=1_gradient_accumulation_steps=8_learning_rate=0.0002_num_train_epochs=4_gradient_checkpointing=True_logging_steps=0.00125_save_steps=0.0625_random_seed=1_lora=True_r=16_alpha=32_dropout=0.05/\"\n",
    "MODEL_PATH = MODEL_CKPT + \"/checkpoint-5316\"\n",
    "DATASET_ID = \"d4nieldev/qpl-completer-ds\"\n",
    "\n",
    "# Load model & tokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(MODEL_PATH, attn_implementation='eager').to('cuda')\n",
    "model = model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50266f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQL Server\n",
    "import pyodbc\n",
    "from src.inference.qpl.qpl_to_cte import flat_qpl_to_cte\n",
    "from src.inference.qpl.validate_qpl import execute_sql, same_rs\n",
    "\n",
    "connection_string = (\n",
    "    'Driver={ODBC Driver 18 for SQL Server};'\n",
    "    'Server=tcp:spider-sql.database.windows.net,1433;'\n",
    "    'Database=test;'\n",
    "    'Uid=iloveqpl;'\n",
    "    'Pwd=P4$$w0rd!;'\n",
    "    'Encrypt=yes;'\n",
    "    'TrustServerCertificate=no;'\n",
    "    'Connection Timeout=30;'\n",
    ")\n",
    "\n",
    "conn = pyodbc.connect(connection_string, autocommit=True)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bddf002",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a950b2",
   "metadata": {},
   "source": [
    "### Line By Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "test_dataset = list(load_dataset(DATASET_ID, split=\"validation\"))\n",
    "prompter = PrompterRegistry.get(DATASET_ID)(with_assistant=False)\n",
    "chat_templates = list(map(prompter.to_chat_template, test_dataset))\n",
    "prompts = list(map(lambda ct: to_model_prompt(tokenizer, ct), chat_templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbca74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete QPL\n",
    "outputs = generate_batch(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_prompts=prompts,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    progress_bar=tqdm(total=len(prompts), desc=\"Completing QPL\"),\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - save outputs\n",
    "import json\n",
    "\n",
    "with open('line_by_line_outputs.json', 'w') as f:\n",
    "    json.dump(outputs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9632ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - load outputs\n",
    "with open('line_by_line_outputs.json', 'r') as f:\n",
    "    outputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate execution accuracy and error rate\n",
    "execution_accuracy = 0\n",
    "gold_errs = 0\n",
    "pred_errs = 0\n",
    "for out, example in tqdm(zip(outputs, test_dataset), desc=\"Evaluating\", total=len(outputs)):\n",
    "    gold = example['prefix_qpl'] + \"\\n\" + example['qpl_line']\n",
    "    pred = example['prefix_qpl'] + \"\\n\" + example['qpl_line'][:example['qpl_line'].index(' = ')+3] + example['op'] + ' ' + out\n",
    "\n",
    "    flat_gold = [line[:line.index('--')] if '--' in line else line for line in gold.split('\\n')]\n",
    "    flat_pred = [line[:line.index('--')] if '--' in line else line for line in pred.split('\\n')]\n",
    "\n",
    "    flat_gold = [l for l in flat_gold if l.strip()]\n",
    "    flat_pred = [l for l in flat_pred if l.strip() and '`' not in l]\n",
    "\n",
    "    gold_cte = flat_qpl_to_cte(flat_gold, example['db_id'])\n",
    "\n",
    "    try:\n",
    "        pred_cte = flat_qpl_to_cte(flat_pred, example['db_id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting prediction to CTE\\n{pred}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print('-'*20)\n",
    "        pred_errs += 1\n",
    "\n",
    "    try:\n",
    "        grs = execute_sql(cursor, gold_cte)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing gold QPL\\n{gold}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print('-'*20)\n",
    "        gold_errs += 1\n",
    "    else:\n",
    "        try:\n",
    "            prs = execute_sql(cursor, pred_cte)\n",
    "            same = same_rs(grs, prs, flat_pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing prediction QPL\\n{pred}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            print('-'*20)\n",
    "            pred_errs += 1\n",
    "\n",
    "    if same:\n",
    "        execution_accuracy += 1\n",
    "\n",
    "print(f\"Execution accuracy: {execution_accuracy}/{len(outputs)} ({execution_accuracy / len(outputs) * 100:.2f}%)\")\n",
    "print(f\"Gold error rate: {gold_errs}/{len(outputs)} ({gold_errs / len(outputs) * 100:.2f}%)\")\n",
    "print(f\"Prediction error rate: {pred_errs}/{len(outputs)} ({pred_errs / len(outputs) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a44d7",
   "metadata": {},
   "source": [
    "### Full Tree With Perfect Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e73670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing QD trees: 100%|██████████| 3027/3027 [00:00<00:00, 158075.60it/s]\n",
      "Completing QPL: 100%|██████████| 3274/3274 [35:12<00:00,  1.28node/s]"
     ]
    }
   ],
   "source": [
    "# Full tree\n",
    "from src.databuilders.completer.build import get_decomposer_roots\n",
    "from src.utils.qpl.tree import PartialQDTree, QPLQDTree\n",
    "from datasets import load_dataset\n",
    "from src.inference.qpl.text_to_qpl import complete\n",
    "\n",
    "# Load and process data\n",
    "def partial_qd_to_qd(tree: PartialQDTree) -> QPLQDTree:\n",
    "    \"\"\"Convert a PartialQDTree to a QPLQDTree.\"\"\"\n",
    "    qd_tree = QPLQDTree(\n",
    "        question=tree.question,\n",
    "        db_id=tree.db_id,\n",
    "        op=tree.op,\n",
    "    )\n",
    "    if tree.children:\n",
    "        qd_tree.children = tuple(partial_qd_to_qd(child) for child in tree.children)\n",
    "        for child in qd_tree.children:\n",
    "            child.parent = qd_tree\n",
    "    return qd_tree\n",
    "\n",
    "\n",
    "decomposer_data = load_dataset(\"bgunlp/question_decomposer_ds\", split=\"validation\")\n",
    "nl2qpl_data = load_dataset('d4nieldev/nl2qpl-ds', split='validation')\n",
    "root_questions = set(row['question'] for row in nl2qpl_data)\n",
    "decomposer_data = [row for row in decomposer_data if row['question'] not in [row['sub_question_1'], row['sub_question_2']]]\n",
    "root_qd_trees = get_decomposer_roots(decomposer_data, root_questions)\n",
    "root_qd_trees = [partial_qd_to_qd(tree) for tree in root_qd_trees]\n",
    "\n",
    "def post_order_index_tree(tree: QPLQDTree, counter: int = 1) -> int:\n",
    "    for child in tree.children:\n",
    "        counter = post_order_index_tree(child, counter)\n",
    "    tree.line_num = counter\n",
    "    return counter + 1\n",
    "\n",
    "for tree in root_qd_trees:\n",
    "    post_order_index_tree(tree)\n",
    "\n",
    "# Complete QPL for each tree\n",
    "complete(\n",
    "    trees=root_qd_trees,\n",
    "    prompter=PrompterRegistry.get(DATASET_ID)(with_assistant=False),\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4ef8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally save outputs\n",
    "import json\n",
    "with open('full_tree_outputs_5316.json', 'w') as f:\n",
    "    json.dump([tree.to_dict() for tree in root_qd_trees], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ccac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - load outputs\n",
    "with open('full_tree_outputs.json', 'r') as f:\n",
    "    root_qd_trees = [QPLQDTree.from_dict(tree) for tree in json.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770732b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate execution accuracy and error rate\n",
    "gold_errs = 0\n",
    "pred_errs = 0\n",
    "execution_accuracy = 0\n",
    "total_pred = 0\n",
    "\n",
    "for example in nl2qpl_data:\n",
    "    trees = [t for t in root_qd_trees if t.question == example['question']]\n",
    "    total_pred += len(trees)\n",
    "    gold = example['query']\n",
    "    for tree in trees:\n",
    "        pred = tree.qpl\n",
    "\n",
    "        flat_pred = [line[:line.index('--')] if '--' in line else line for line in pred.split('\\n')]\n",
    "        flat_pred = [l for l in flat_pred if l.strip() and '`' not in l]\n",
    "\n",
    "        try:\n",
    "            pred_cte = flat_qpl_to_cte(flat_pred, tree.db_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting prediction to CTE\\n{pred}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            print(tree.db_id)\n",
    "            print('-'*20)\n",
    "            pred_errs += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            grs = execute_sql(cursor, gold)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing gold QPL\\n{gold}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            print('-'*20)\n",
    "            gold_errs += 1\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                prs = execute_sql(cursor, pred_cte)\n",
    "                same = same_rs(grs, prs, flat_pred)\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing prediction QPL\\n{pred}\")\n",
    "                print(f\"Error: {e}\")\n",
    "                print('-'*20)\n",
    "                pred_errs += 1\n",
    "                continue\n",
    "        \n",
    "        if same:\n",
    "            execution_accuracy += 1\n",
    "\n",
    "print(f\"Execution accuracy: {execution_accuracy}/{total_pred} ({execution_accuracy / total_pred * 100:.2f}%)\")\n",
    "print(f\"Gold errors: {gold_errs}/{total_pred} ({gold_errs / total_pred * 100:.2f}%)\")\n",
    "print(f\"Prediction errors: {pred_errs}/{total_pred} ({pred_errs / total_pred * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf8ff4",
   "metadata": {},
   "source": [
    "### Rule Based (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "prompter = PrompterRegistry.get(DATASET_ID)(with_assistant=True)\n",
    "chat_templates = []\n",
    "for example in test_dataset:\n",
    "    chat_templates.append(prompter.to_chat_template(example))\n",
    "\n",
    "\n",
    "def equivalent_bracketed_lines(\n",
    "        true_line: str,\n",
    "        generated_line: str,\n",
    "        *,\n",
    "        require_exact_names: bool = False,\n",
    "        ignore_case: bool = True\n",
    "    ) -> bool:\n",
    "    _ZERO_DECIMAL = re.compile(r'(?<![\\d.])(\\d+)\\.0+\\b')\n",
    "    _TABLE_COL    = re.compile(r'#\\d+\\.\\s*[\\w$]+', flags=re.I)\n",
    "    _EQUALITY     = re.compile(rf'({_TABLE_COL.pattern})\\s*=\\s*({_TABLE_COL.pattern})', flags=re.I)\n",
    "\n",
    "    def _norm_nums(txt: str) -> str:\n",
    "        return _ZERO_DECIMAL.sub(r'\\1', txt)\n",
    "\n",
    "    # ---- build equivalence classes from join predicates\n",
    "    def _build_equiv_map(*lines: str) -> dict[str, str]:\n",
    "        parent = {}\n",
    "\n",
    "        def find(x):\n",
    "            parent.setdefault(x, x)\n",
    "            if parent[x] != x:\n",
    "                parent[x] = find(parent[x])\n",
    "            return parent[x]\n",
    "\n",
    "        def union(a, b):\n",
    "            ra, rb = find(a), find(b)\n",
    "            if ra != rb:\n",
    "                parent[rb] = ra\n",
    "\n",
    "        for line in lines:\n",
    "            for block in re.findall(r'Predicate\\s*\\[([^\\]]*)\\]',\n",
    "                                    _norm_nums(line), flags=re.I):\n",
    "                for left, right in _EQUALITY.findall(block):\n",
    "                    l = left.replace(' ', '')\n",
    "                    r = right.replace(' ', '')\n",
    "                    if ignore_case:\n",
    "                        l, r = l.upper(), r.upper()\n",
    "                    union(l, r)\n",
    "\n",
    "        equiv = {}\n",
    "        for full in parent:\n",
    "            col = full.split('.', 1)[1]\n",
    "            root = find(full)\n",
    "            equiv[full] = col.upper() if ignore_case else col\n",
    "            if root not in equiv:\n",
    "                equiv[root] = equiv[full]\n",
    "        return equiv\n",
    "\n",
    "    EQUIV = _build_equiv_map(true_line, generated_line)\n",
    "\n",
    "    # ---- compare skeletons (outside brackets)\n",
    "    def _skeleton(txt: str) -> str:\n",
    "        txt = _norm_nums(txt)\n",
    "        txt = re.sub(r'\\[[^\\]]*]', '[]', txt)\n",
    "        txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "        return txt.upper() if ignore_case else txt\n",
    "\n",
    "    if _skeleton(true_line) != _skeleton(generated_line):\n",
    "        return False\n",
    "\n",
    "    # ---- helper to extract bracket contents\n",
    "    blocks = lambda s: re.findall(r'\\[([^\\]]*)]', _norm_nums(s))\n",
    "\n",
    "    t_blocks, g_blocks = blocks(true_line), blocks(generated_line)\n",
    "    if len(t_blocks) != len(g_blocks):\n",
    "        return False\n",
    "\n",
    "    # ---- canonicalise individual tokens\n",
    "    def canon(tok: str) -> str:\n",
    "        tok = re.split(r'\\s+AS\\s+', tok, flags=re.I)[0]\n",
    "        tok = re.sub(r'\\s+', ' ', tok).strip()\n",
    "        tok = _norm_nums(tok)\n",
    "\n",
    "        def repl(m):\n",
    "            key = m.group(0).replace(' ', '')\n",
    "            key = key.upper() if ignore_case else key\n",
    "            return EQUIV.get(key, m.group(0))\n",
    "\n",
    "        tok = _TABLE_COL.sub(repl, tok)\n",
    "        return tok.upper() if ignore_case else tok\n",
    "\n",
    "    # ---- compare each corresponding block\n",
    "    for tb, gb in zip(t_blocks, g_blocks):\n",
    "        t_set = {canon(tok) for tok in tb.split(',') if tok.strip()}\n",
    "        g_set = {canon(tok) for tok in gb.split(',') if tok.strip()}\n",
    "\n",
    "        if require_exact_names:\n",
    "            if t_set != g_set:\n",
    "                return False\n",
    "        else:\n",
    "            if not t_set.issubset(g_set):\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "acc = 0\n",
    "for out, chat_template, example in tqdm(zip(outputs, chat_templates, test_dataset), desc=\"Evaluating\", total=len(outputs)):\n",
    "    label = chat_template['messages'][-1]['content']\n",
    "    equivalent = equivalent_bracketed_lines(\n",
    "        label,\n",
    "        out,\n",
    "    )\n",
    "    if not equivalent:\n",
    "        print(\"Question:\")\n",
    "        print(example['question'])\n",
    "        print('-'*40)\n",
    "        print(\"Predicted:\")\n",
    "        print(example['op'], out)\n",
    "        print('-'*40)\n",
    "        print(\"True:\")\n",
    "        print(example['op'], label)\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        acc += 1\n",
    "\n",
    "print(f\"Accuracy: {acc}/{len(outputs)} = {acc / len(outputs) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
